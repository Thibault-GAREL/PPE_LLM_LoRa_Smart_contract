# Fine-tuning de LLaMA avec LoRA pour la Classification de Vuln√©rabilit√©s Solidity

Ce projet permet de fine-tuner le mod√®le LLaMA avec la technique LoRA (Low-Rank Adaptation) pour classifier les vuln√©rabilit√©s dans les smart contracts Solidity.

## üìã Pr√©requis

### Mat√©riel
- **GPU recommand√©** : NVIDIA GPU avec au moins 8GB de VRAM (16GB+ id√©al)
- **RAM** : Au moins 16GB
- **Espace disque** : ~20GB pour le mod√®le et les donn√©es

### Logiciels
- Python 3.8+
- CUDA 11.8+ (pour l'utilisation GPU)
- pip

## üöÄ Installation

### 1. Cr√©er un environnement virtuel (recommand√©)

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

### 2. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 3. V√©rifier l'installation de PyTorch avec CUDA

```bash
python -c "import torch; print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

## üìä Pr√©paration des donn√©es

Assurez-vous d'avoir le dataset `SC_Vuln_8label.csv` dans le dossier `archive/` avec la structure suivante :
- `filename` : nom du fichier
- `code` : code Solidity du contrat
- `label_encoded` : label de la vuln√©rabilit√© (0-8)

Les 9 classes de vuln√©rabilit√©s :
- 0: Block number dependency (BN)
- 1: Dangerous delegatecall (DE)
- 2: Ether frozen (EF)
- 3: Ether strict equality (SE)
- 4: Integer overflow (OF)
- 5: Reentrancy (RE)
- 6: Timestamp dependency (TP)
- 7: Unchecked external call (UC)
- 8: Normal (sans vuln√©rabilit√©)

## üèãÔ∏è Entra√Ænement du mod√®le

### Configuration de base

Modifiez les param√®tres dans `fine_tune_llama_lora.py` si n√©cessaire :

```python
CONFIG = {
    "model_name": "meta-llama/Llama-3.2-3B",  # Mod√®le de base
    "num_train_epochs": 3,                     # Nombre d'√©poques
    "lora_r": 16,                              # Rang LoRA
    "learning_rate": 2e-4,                     # Taux d'apprentissage
    # ... autres param√®tres
}
```

### Lancer l'entra√Ænement

```bash
python fine_tune_llama_lora.py
```

**Important** : Si vous n'avez pas acc√®s au mod√®le LLaMA officiel, vous pouvez utiliser des alternatives open-source :
- `TinyLlama/TinyLlama-1.1B-Chat-v1.0` (plus l√©ger, ~1GB)
- `microsoft/phi-2` (2.7B param√®tres)

Modifiez simplement `CONFIG["model_name"]` dans le script.

### Dur√©e estim√©e

- Avec GPU RTX 3090 (24GB) : ~2-4 heures pour 3 √©poques
- Avec GPU RTX 3060 (12GB) : ~4-8 heures
- Avec CPU (non recommand√©) : plusieurs jours

### R√©duction de la m√©moire

Si vous manquez de VRAM, r√©duisez :
```python
"per_device_train_batch_size": 2,  # au lieu de 4
"gradient_accumulation_steps": 8,  # au lieu de 4
"max_length": 1024,                # au lieu de 2048
```

## üîÆ Utilisation du mod√®le fine-tun√©

### Mode batch (classifier un CSV entier)

```bash
python inference_lora.py archive/SC_Vuln_8label.csv resultats.csv
```

### Mode interactif

```bash
python inference_lora.py
```

Puis collez votre code Solidity et tapez `END` pour obtenir la pr√©diction.

### Exemple d'utilisation en Python

```python
from inference_lora import load_finetuned_model, classify_contract

# Charger le mod√®le
model, tokenizer = load_finetuned_model(
    "meta-llama/Llama-3.2-3B",
    "./llama_lora_solidity_finetuned/final_model"
)

# Classifier un contrat
code_solidity = """
pragma solidity ^0.4.0;
contract MyContract {
    function withdraw() public {
        msg.sender.call.value(balance)();
        balance = 0;
    }
}
"""

prediction = classify_contract(model, tokenizer, code_solidity)
print(f"Vuln√©rabilit√© d√©tect√©e : {prediction}")
```

## üìà R√©sultats attendus

Apr√®s le fine-tuning, vous devriez obtenir :
- **Pr√©cision baseline (LLaMA non fine-tun√©)** : ~30-40%
- **Pr√©cision apr√®s fine-tuning** : ~70-85%+ (selon le dataset et les hyperparam√®tres)

Les r√©sultats sont sauvegard√©s dans `llama_lora_solidity_finetuned/` :
- `final_model/` : poids LoRA du mod√®le
- `predictions.csv` : pr√©dictions sur le test set
- `training_config.json` : configuration de l'entra√Ænement

## ‚öôÔ∏è Optimisations avanc√©es

### 1. Ajuster les hyperparam√®tres LoRA

```python
"lora_r": 32,        # Augmenter pour plus de capacit√© (mais plus de m√©moire)
"lora_alpha": 64,    # Double de lora_r g√©n√©ralement
"lora_dropout": 0.1, # Augmenter si overfitting
```

### 2. Modules cibles suppl√©mentaires

```python
"target_modules": [
    "q_proj", "k_proj", "v_proj", "o_proj",
    "gate_proj", "up_proj", "down_proj"  # Pour MLP aussi
]
```

### 3. Learning rate scheduling

```python
"lr_scheduler_type": "cosine",      # ou "linear", "polynomial"
"warmup_ratio": 0.05,               # 5% des steps en warmup
```

### 4. Data augmentation

Vous pouvez augmenter artificiellement le dataset en :
- Reformulant les prompts
- Ajoutant du bruit contr√¥l√© au code
- Utilisant des variations de formatting

## üêõ D√©pannage

### Erreur CUDA Out of Memory
```python
# R√©duire la taille des batchs
"per_device_train_batch_size": 1,
"gradient_accumulation_steps": 16,

# Ou utiliser une quantification plus agressive
"use_4bit": True,
```

### Mod√®le LLaMA non accessible
Utilisez une alternative open-source :
```python
"model_name": "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
```

### Entra√Ænement tr√®s lent
- V√©rifiez que vous utilisez bien le GPU : `torch.cuda.is_available()`
- R√©duisez `max_length` √† 1024 ou 512
- Augmentez `gradient_accumulation_steps`

### Pr√©cision faible apr√®s entra√Ænement
- Augmentez le nombre d'√©poques
- Ajustez le learning rate (essayez 1e-4 ou 3e-4)
- V√©rifiez la distribution des classes (d√©s√©quilibre ?)

## üìù Structure des fichiers

```
.
‚îú‚îÄ‚îÄ fine_tune_llama_lora.py      # Script d'entra√Ænement principal
‚îú‚îÄ‚îÄ inference_lora.py            # Script d'inf√©rence
‚îú‚îÄ‚îÄ requirements.txt             # D√©pendances
‚îú‚îÄ‚îÄ README.md                    # Ce fichier
‚îú‚îÄ‚îÄ archive/
‚îÇ   ‚îî‚îÄ‚îÄ SC_Vuln_8label.csv      # Dataset d'entra√Ænement
‚îî‚îÄ‚îÄ llama_lora_solidity_finetuned/
    ‚îú‚îÄ‚îÄ final_model/            # Mod√®le fine-tun√©
    ‚îú‚îÄ‚îÄ predictions.csv         # R√©sultats
    ‚îî‚îÄ‚îÄ training_config.json    # Configuration
```

## üîç Monitoring de l'entra√Ænement

Pour suivre l'entra√Ænement en temps r√©el, installez TensorBoard :

```bash
pip install tensorboard
tensorboard --logdir=llama_lora_solidity_finetuned
```

## üìö Ressources suppl√©mentaires

- [Documentation LoRA](https://arxiv.org/abs/2106.09685)
- [Hugging Face PEFT](https://huggingface.co/docs/peft)
- [LLaMA](https://ai.meta.com/llama/)

## üí° Astuces

1. **Commencez petit** : Testez d'abord avec un petit subset (100-500 contrats) pour valider le pipeline
2. **Sauvegardez souvent** : Utilisez `save_steps=100` pour ne pas perdre de progr√®s
3. **Monitorer la loss** : Si elle ne descend pas, ajustez le learning rate
4. **Test early stopping** : Si la validation loss augmente, arr√™tez l'entra√Ænement

## ‚öñÔ∏è Licence

Ce code est fourni √† des fins √©ducatives et de recherche.

## ü§ù Contribution

Les am√©liorations sont les bienvenues ! N'h√©sitez pas √† ouvrir des issues ou des pull requests.
